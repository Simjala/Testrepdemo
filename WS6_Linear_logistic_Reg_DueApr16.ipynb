{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Doing all the imports for you\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = np.genfromtxt('RRLyrae_features_small.txt',delimiter=',')\n",
    "Y = np.genfromtxt('RRLyrae_labels_small.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(483, 2000)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(Y>0), np.sum(Y==0) # This \"small\" data set is more balanced than the original"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1\\. This data set contains four features and the RR Lyrae designation (0/1). Which one would you think makes a better model, linear regression or logistic regression, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Build a logistic regression model with 5-fold cross validation; you can use the function cross_val_predict (an example of the usage can be found in the Special Report 2 notebook) to build the array with the predicted labels. Report the r2_score. Save the array with the predictions because you will need it later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Now build a linear regression model with 5-fold cross validation just as above; report the r2_score. Save the array with the predictions because you will need it later. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Plot the histograms of the \"prediction\" arrays for logistic and linear regression. Remember to use labels to identify the two distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. How do the predictions differ? Which of the two models is essentially behaving like a classifier, and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Logistic Regression model also has an option called \"predict.proba\", demonstrated in the code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Class')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYShIkhqGgiSp8f8BFoHykPHr+JwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, random_state=0)\n",
    "model2 = LogisticRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "probs = model2.predict_proba(X_test)\n",
    "pred = model2.predict(X_test)\n",
    "\n",
    "plt.scatter(probs[:,0], pred);\n",
    "plt.xlabel('Probability')\n",
    "plt.ylabel('Class')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Based on the code and figure above, what is the difference between using\"predict\" and \"predict_proba\"? What is the probability value that corresponds to transitioning from one class to the other?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7\\. For this second part, we are going to use the \"study hours data set\" from the Linear Regression part (you can find the data set, called data_students_hours.csv, on Blackboard). Define an array x (features) with the first column of this file and an array y (labels) with the second column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8 \\. In the linear regression notebook, we went through an example and calculated the model coefficients of a linear regression model applied to these data. In the plot of the best fit line, what is the meaning of m and b?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9\\. However these can also be calculated by hand using the formulas on the linear regression slides. Code up the formulas below and report your coefficients for slope and intercept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/latex": [
       "\n",
       "\\begin{equation}\n",
       "\n",
       "S S_{xy} = \\sum x_i y_i - (\\sum x_i \\sum y_i)/n \\\\\n",
       "\n",
       "S S_{xx} = \\sum x_i^2 - (\\sum x_i)^2 / n \\\\\n",
       "\n",
       "m = S S_{xy}/ S S_{xx} \\\\\n",
       "\n",
       "b = \\bar{y} - m * \\bar{x}\n",
       "\n",
       "\\end{equation}\n",
       "\n",
       "where n = number of points and the overhead bar represent the mean.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Latex object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%latex\n",
    "\n",
    "\\begin{equation}\n",
    "\n",
    "S S_{xy} = \\sum x_i y_i - (\\sum x_i \\sum y_i)/n \\\\\n",
    "\n",
    "S S_{xx} = \\sum x_i^2 - (\\sum x_i)^2 / n \\\\\n",
    "\n",
    "m = S S_{xy}/ S S_{xx} \\\\\n",
    "\n",
    "b = \\bar{y} - m * \\bar{x}\n",
    "\n",
    "\\end{equation}\n",
    "\n",
    "where n = number of points and the overhead bar represent the mean.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10\\. Looking at the data (hours vs scores), do you think it would make sense to fit these data using a logistic regression model? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extra credit: Run the gradient descent notebook and report the coefficients you found here. Calculate the cost function (found in the linear regression notebook) for the slope, intercept values you found with the gradient descent method and the values you found above, using the formulas. Which set of values is best? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
